# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CNInJEEWrial-M7DNlgggk6qyu6QMTfL
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://www-us.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz
!tar xf spark-2.4.7-bin-hadoop2.7.tgz #descomprime el fichero
!pip install -q findspark #instala spark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64" #funciones dels sistema de python para cambiar variables de entorno y que funcione
os.environ["SPARK_HOME"] = "/content/spark-2.4.7-bin-hadoop2.7"
import findspark #para tener un contexto spark donde trabajar
findspark.init()
from pyspark import SparkContext
sc = SparkContext()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate() #para generar una spark sesion sql

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

nba = sc.textFile("partidosLigaNBA.csv") #cargar el dataset como RDD

nba.count() #función para contar, en una RDD, cuántas filas hay

nba.take(7)

top_nba = nba.take(1)[0] 
nba_filter = nba.filter(lambda x: x != top_nba) 
nba_filter.take(7)

#separar por : con map

nba_filter = nba.filter(lambda x: x != top_nba).map(lambda x: x.split(":")) #Realizamos el split para que nos separe las columnas 
nba_filter.take(7)

nba_filter = nba.filter(lambda x: x != top_nba).map(lambda x: x.split(":")[-1]) 
nba_filter.take(7)

#Selección del elemento del vector generado, y casteado a numérico.

nba_filter = nba.filter(lambda v: v != top_nba) \
                      .map(lambda v: v.split(":")[-1]) \
                      .filter(lambda v_visit: v_visit.isdigit()) \
                      .map(lambda v_dest: int(v_dest))

#Comprobación de que todos los valores son dígitos.
for i in range(500):
  print(type(nba_filter.take(500)[i])) #Intervalo elegido para el histograma

nba_filter.take(500)

difMaxMin =  (nba_filter.max() - nba_filter.min()) / 5 #Calculo el rango haciendo la diferencia entre el número mayor (168) y el menor (59), que tiene que tener cada intervalo para poder dividirlo en 5 subgrupos
difMaxMin

#Definimos la función intervalo, pasándole por parámetro el dato, para que lo clasifique en un tipo

def interval(dato):
  if dato< 80.8 :
    return 'int 1'
  elif dato < 102.6:
    return 'int 2'
  elif dato <124.4:
    return 'int 3'
  elif dato <146.2:
    return 'int 4'
  elif dato <=168:
   return 'int 5'

nba_filter_interval = nba.filter(lambda s: s != top_nba) \
                      .map(lambda s: s.split(":")[-1]) \
                      .filter(lambda s_pvisit: s_pvisit.isdigit()) \
                      .map(lambda d_pvisit: int(d_pvisit)) \
                      .map(lambda x : (interval(x),1)) \
                      .reduceByKey(lambda a, b: a + b) \
                      .collect()

nba_filter_interval.sort() #Ordenamos los intervalos
nba_filter_interval

valores = [476,6412,5549,454,6]
nombres = ["Grupo 1","Grupo 2","Grupo 3","Grupo 4","Grupo 5"]
colores = ["#EE6055","#60D394","#AAF683","#FFD97D","#FF9B85"]
plt.pie(valores, labels=nombres, autopct="%0.1f %%", colors=colores)
plt.axis("equal")
plt.show()

df_nba_filter_interval = pd.DataFrame(nba_filter_interval) #Lo convertimos a DataFrame

labels, ys = zip(*nba_filter_interval)
xs = np.arange(len(labels)) 
width = 1

plt.bar(xs, ys, width, align='center', alpha=1, edgecolor = 'black',  linewidth=1)

plt.xticks(xs, labels) #Replace default x-ticks with xs, then replace xs with labels
plt.yticks(ys)

