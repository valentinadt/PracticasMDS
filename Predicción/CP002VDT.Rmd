---
title: "CP02: Salarios NBA (CV y Regularización)"
author: "Valentina Díaz Torres"
date: "11/8/2020"
output:
  prettydoc::html_pretty:
    theme: cayman
  html_document:
    df_print: paged
---


## Introducción
El objetivo es utilizar las técnicas de cross validation y regularización para seleccionar el mejor modelo desde un punto de vista predictivo.


```{r, message=FALSE}

library(tidyverse)
library(broom) # modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # estimar gam
library(reshape2) # melt
library(janitor) # Clean names
library(skimr)
library(here) # Comentar
library(tidyverse)
library(magrittr) # Pipe operators
library(leaps) # Model selection
library(rsample)
library(glmnet)
```


```{r Read Data}

#Carga de datos

nba <-read.csv("nba.csv")
colnames(nba)

#Limpieza de datos 

nba %<>% clean_names()
colnames(nba)

#Summarize datos

skim(nba)

#Eliminar duplicados

nba%<>% distinct(player,.keep_all= TRUE)

#Eliminar NA

nba %<>% drop_na()
```


```{r data1 , message=FALSE}

#Eliminamos las variables que no voy a usar, por ser categóricas y además, aplicamos a la variable dependiente el logaritmo.

log_nba <- nba %>% mutate(salary=log(salary))
vars <- c("player","nba_country","tm")
log_nba <- log_nba %>%
  select_at(vars(-vars))
```


## Cross Validation

```{r }
set.seed(123) #crear una muestra
nba_split <- initial_split(log_nba, prop = 0.70, strata = "salary")
#division de la muestra en un 70% para training y un 30% restante para test.
nba_train <- training(nba_split)
nba_test <- testing (nba_split)
#asignamos valores para x e y de training y de test.
nba_train_x <- model.matrix(salary~., nba_train)[,-1] #En la variable con x se almacena la matriz correspondiente a la variable salary
nba_train_y <- log(nba_train$salary) #En la variablel con y se almacena el valor resultante de aplicar el logaritmo a la variable salary

nba_test_x <- model.matrix(salary~., nba_test)[,-1]
nba_test_y <-  log(nba_test$salary)
#Comprobamos dimension
dim(nba_train_x)
```

## Ridge

```{r }
set.seed(123)
#Realizamos el mismo procedimiento que en el apartado anterior, salvo que para realizar el Ridge, el valor de Alpha para el modelo es igual a 0.

nba_split <- initial_split(nba, prop = .7, strata = "salary") 
nba_train <- training(nba_split)
nba_test  <- testing(nba_split)
nba_train_x <- model.matrix(salary ~ ., nba_train)[, -1]
nba_train_y <- log(nba_train$salary)

nba_test_x <- model.matrix(salary ~ ., nba_test)[, -1]
nba_test_y <- log(nba_test$salary)

dim(nba_train_x)

nba_ridge <- glmnet(
  x = nba_train_x,
  y = nba_train_y,
  alpha = 0
)

#Visualizamos el Ridge

plot(nba_ridge, xvar = "lambda")
```


```{r }

#coeficiente de Ridge

ridgeCoef= nba_ridge %>% tidy()
ridgeCoef
nba_mtx = model.matrix(salary~., data = nba)

#Elección Lambda Óptimo

ridge_cv=cv.glmnet(x=nba_mtx,y=nba$salary,alpha=0, standardize = T)
plot(ridge_cv)

# Selección lambda óptimo
ridge_lambda_opt = ridge_cv$lambda.min

# Entrenamiento modelo óptimo
ridge_opt = glmnet(x=nba_mtx, # Matriz de regresores
                 y=nba$salary, #Vector de la variable
                 alpha=0, 
                 standardize = TRUE,
                 lambda = ridge_lambda_opt)

ridge_opt

# Tidy

ridge_opt %>% tidy()


```

## Lasso


```{r}

#Para el modelo Lasso, Alpha cambia su valor a 1.

nba_lasso <- glmnet(
  x = nba_train_x,
  y = nba_train_y,
  alpha = 1
)
plot(nba_lasso, xvar = "lambda")


```

Como se puede apreciar en ambas gráficas, los coeficientes se aproximan a 0, que es la línea central, en los dos casos. La diferencia entre Ridge y Lasso es que, aunque ambos aproximan a cero los predictores, el primero puede excluir valores de los mismos, mientras que el segundo no excluye ninguno.

```{r}
#Comprobamos los coeficientes obtenidos con Lasso

coefLasso = nba_lasso %>% tidy()

coefLasso


```
Se puede observar que hay una gran diferencia entre los coeficientes de Lasso y de Ridge


## Elastic Net


```{r data4}

#Usamos glmnet para ajustar 

lasso    <- glmnet(nba_train_x, nba_train_y, alpha = 1.0) 
elastic1 <- glmnet(nba_train_x, nba_train_y, alpha = 0.25) 
elastic2 <- glmnet(nba_train_x, nba_train_y, alpha = 0.75) 
ridge    <- glmnet(nba_train_x, nba_train_y, alpha = 0.0)


par(mfrow = c(2, 2), mar = c(1,1,1,1) + 0.1)
plot(lasso, xvar = "lambda", main = "Lasso (Alpha = 1)\n\n\n")
plot(elastic1, xvar = "lambda", main = "Elastic Net (Alpha = .25)\n\n\n")
plot(elastic2, xvar = "lambda", main = "Elastic Net (Alpha = .75)\n\n\n")
plot(ridge, xvar = "lambda", main = "Ridge (Alpha = 0)\n\n\n")

```

Al hacer elastic net, se le asigna distintos alphas, 1 en el caso de lasso, 0 en ridge y a elastic1 y 2 se le atribuyen 0.75 y 0.25, repartiendo el 100% entre ambos. En las gráficas de después quedan resumidas y representadas los diferentes modelos, siendo ridge el más representativo y los dos elastic más próximos al gráfico de lasso.

## Conclusiones


El modelo Elastic net nos ha mostrado las penalizaciones de Ridge por un lado, cuando alpha es igual a 0 y Lasso cuando esta es igual a 1. Con este cambio, se regula la penalización de cada uno.

Podemos concluir que, como en este modelo han sido más cercanos, los valores de los coeficientes a 1 que 0, es más importante la penalización de tipo Lasso, por la cual podríamos estimar de un mejor modo el modelo de salarios para la NBA.



